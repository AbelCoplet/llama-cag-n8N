############
# llama-cag-n8n Configuration
############

# System Configuration
CONFIG_PROFILE=cpu       # Options: cpu, gpu-nvidia (Linux only)

############
# llama.cpp Configuration - LARGE CONTEXT WINDOW MODEL SETTINGS
############

# Paths (required)
LLAMACPP_PATH=~/Documents/llama.cpp
LLAMACPP_MODEL_PATH=~/Documents/llama.cpp/models/gemma-4b.gguf
LLAMACPP_MODEL_NAME=gemma-4b.gguf  # Just the filename, used in workflows
LLAMACPP_KV_CACHE_DIR=~/cag_project/kv_caches
LLAMACPP_TEMP_DIR=~/cag_project/temp_chunks

# Large context window settings - CRITICAL FOR CAG PERFORMANCE
LLAMACPP_MAX_CONTEXT=128000 # 128K context window (set to match your model)
LLAMACPP_GPU_LAYERS=0       # Mac: keep at 0, Linux with GPU: 33 recommended
LLAMACPP_THREADS=4          # Number of CPU threads (set to match your CPU)
LLAMACPP_BATCH_SIZE=1024    # Batch size for processing large documents

############
# Database Configuration (required) - CHANGE THE PASSWORD!
############

DB_TYPE=postgres
DB_HOST=db
DB_PORT=5432
DB_NAME=llamacag
DB_USER=llamacag
DB_PASSWORD=your_secure_password_here  # CHANGE THIS

############
# n8n Configuration (required) - CHANGE THESE SECRETS!
############

N8N_HOST=localhost
N8N_PORT=5678
N8N_PROTOCOL=http
N8N_ENCRYPTION_KEY=your-secure-encryption-key  # CHANGE THIS
N8N_USER_MANAGEMENT_JWT_SECRET=your-jwt-secret  # CHANGE THIS

############
# Document Processing Settings
############

# Document watch folder
DOCUMENTS_FOLDER=~/Documents/cag_documents

# Advanced settings for large document processing
MAX_CHUNK_SIZE=40000        # Larger chunks for CAG (character count)
CHUNK_OVERLAP=500           # Overlap between chunks if needed
MIN_DOCUMENT_SIZE_FOR_CHUNKING=100000  # Only chunk very large documents