{
  "name": "KV CACHE MANAGEMENT",
  "nodes": [
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "documentPath",
              "value": "/data/documents/sample.pdf"
            },
            {
              "name": "documentId",
              "value": "sample-document"
            },
            {
              "name": "kvCachePath",
              "value": "/data/kv_caches/sample_cache.bin"
            },
            {
              "name": "tempFilePath",
              "value": "/data/temp_chunks/sample-document-temp.pdf"
            }
          ],
          "boolean": [
            {
              "name": "setAsMaster",
              "value": true
            }
          ]
        },
        "options": {}
      },
      "name": "Set Workflow Params",
      "type": "n8n-nodes-base.set",
      "typeVersion": 1,
      "position": [
        -660,
        -700
      ],
      "id": "894c0627-d7f2-46df-9891-25c2af528c0a"
    },
    {
      "parameters": {
        "url": "http://cag-bridge:8000/create-cache",
        "jsonParameters": true,
        "options": {
          "timeout": 60000
        }
      },
      "name": "Call CAG Bridge",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        -60,
        -700
      ],
      "id": "696e9e19-6fe5-4700-81f9-cc75479a2344"
    },
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "status",
              "value": "={{$json.success ? '✅ KV Cache created successfully!' : '❌ KV Cache creation failed!'}}"
            },
            {
              "name": "response",
              "value": "={{JSON.stringify($json)}}"
            }
          ]
        },
        "options": {}
      },
      "name": "Workflow Result",
      "type": "n8n-nodes-base.set",
      "typeVersion": 1,
      "position": [
        140,
        -700
      ],
      "id": "109c99ab-927b-478a-8aad-1f5d25c379c8"
    },
    {
      "parameters": {},
      "name": "Read Document File1",
      "type": "n8n-nodes-base.readBinaryFile",
      "typeVersion": 1,
      "position": [
        -460,
        -700
      ],
      "id": "8358b1b6-c7ae-4fc4-abaa-ec2788d33f09"
    },
    {
      "parameters": {
        "options": {}
      },
      "name": "Write Temp File1",
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        -260,
        -700
      ],
      "id": "3b1fa22d-b788-4421-88ba-8a8e57aac7f2"
    },
    {
      "parameters": {
        "content": "## Document Upload\n\nWorkflow Steps\n\n1.  Trigger\n\nInitiate the workflow on document upload. for Local Setup on File upload, and or Google Drive Change\n\n2. Set Document Parameters (Set Node)\n\nClearly define essential parameters:\n\ndocumentPath: Full path to your source document, e.g., /data/documents/myfile.pdf\n\ndocumentId: A unique identifier for your document, e.g., important-doc\n\nkvCachePath: Destination path for storing the generated KV cache, e.g., /data/kv_caches/important-doc_cache.bin\n\ntempFilePath: Temporary storage path, e.g., /data/temp_chunks/important-doc_temp.pdf\n\nestimatedTokens: Approximate token count (for context sizing), e.g., 4000\n\nsetAsMaster: Boolean indicating if this KV cache should be the primary knowledge base\n\n3. Read Binary File (Read Binary File Node)\n\nReads the document from the provided documentPath.\n\nOutputs binary data to pass to the next node.\n\n4. Write Binary File (Write Binary File Node)\n\nWrites the binary data from the previous node to a temporary location (tempFilePath).\n\nEnsures a clear and accessible location for subsequent processing.\n\n5. Create KV Cache (HTTP Request Node)\n\nSends a structured JSON payload via POST request to the CAG Bridge endpoint (/create-cache).\n\nJSON payload includes:\n\ndocumentId\n\ntempFilePath\n\nkvCachePath\n\nestimatedTokens\n\nsetAsMaster\n\nThe bridge processes the temporary file to create and optionally set the KV cache as master.",
        "height": 1060,
        "width": 1640,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1160,
        -720
      ],
      "id": "89e3f720-1695-41c9-bc24-38c4ade20080",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "content": "## Updating KV Cache\nNo manual purging is required when you want to replace or update the document in your KV cache.\nThe workflow you've established (with your CAG Bridge and associated scripts) is already designed to handle this smoothly and transparently.\nWhen You Want to Replace or Update a Document:\nYou simply need to:\n\nRun the workflow again.\nProvide the updated document (same path is fine if overwritten, or new path if different).\nSet the parameter setAsMaster to true if you want this new cache to replace the current master KV cache.\nWhat Happens Internally:\n\nYour create_kv_cache.sh script overwrites the KV cache at the given kvCachePath if the path already exists​\n.\nIf you've set setAsMaster to true, your CAG Bridge service will automatically copy the newly created KV cache to the master cache location (master_cache.bin), replacing the existing master cache​\n.\nSummary:\nAction Needed\tWorkflow Step\tManual Purging Required?\nReplace existing cache\tRun workflow again\tNo ✅\nUpdate document content\tRun workflow again\tNo ✅\nSet new master cache\tSet setAsMaster to true\tNo ✅\n",
        "height": 1060,
        "width": 480,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1640,
        -720
      ],
      "id": "8e991490-3bc0-486d-9b6e-2cc7c207a78a",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "content": "Detailed Setup Instructions for Claude Document Optimizer Workflow\nStep-by-Step Configuration Guide( With HTTP node)\n1. Manual Trigger:\n\nStart the workflow manually.\nNo configuration needed.\n\n2. Set Document Path:\n\nConfigure the string value for documentPath to point to your input document (e.g., /data/documents/input.pdf).\nThis is where your document is located in the file system.\n\n3. Read Binary File:\n\nThis node automatically reads the document from the path specified in the previous node.\nNo additional configuration needed as the path is dynamically set from $json.documentPath.\n\n4. Initial Text Cleanup:\n\nAutomatically cleans excess whitespace and formats the text.\nEstimates token count and checks if the document exceeds Claude's token limits.\nNo user input required.\n\n5. Document Too Large?:\n\nThis node automatically branches based on document size.\nNo configuration needed.\nIf document is too large, it will follow the \"Split Document\" path.\nIf document is within size limits, it proceeds to \"Prepare Claude API Request\".\n\n6. Prepare Claude API Request:\n\nAutomatically creates the optimized prompts for Claude.\nNo configuration needed.\nIncludes both system message and user prompt formatted for document optimization.\n\n7. Claude API (HTTP Request):\n\nURL: https://api.anthropic.com/v1/messages\nMethod: POST\nAuthentication: Set to \"Generic credential type\"\nGeneric Auth Type: Select \"HTTP Header Auth\"\nNode Credential Name: Select your \"Anthropic API\" credential\nHeaders:\n\nanthropic-version: 2023-06-01\ncontent-type: application/json\nx-api-key: ={{ $credential.apiKey }}\n\n\nBody: Ensure the following JSON is entered exactly as shown:\n\njsonCopier{\n  \"model\": \"claude-3-7-sonnet-20250219\",\n  \"max_tokens\": 128000,\n  \"temperature\": 0.1,\n  \"system\": \"{{ $json.anthropicSystemPrompt }}\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"{{ $json.anthropicUserPrompt }}\"\n    }\n  ]\n}\n8. Process Claude Response:\n\nAutomatically extracts the optimized text from Claude's response.\nCalculates token reduction statistics.\nNo user input required.\n\n9. Write Optimized Document:\n\nAutomatically saves the optimized document to /data/documents/optimized/.\nThe filename will include the original filename and a timestamp.\nNo additional configuration needed.\n\n10. Generate Optimization Summary:\n\nCreates a summary report showing token reduction statistics.\nNo configuration needed.",
        "height": 1700,
        "width": 680
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2320,
        -1360
      ],
      "id": "3bdd72b0-7815-4737-856d-a399d8e85adc",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "documentPath",
              "value": "/data/documents/input.pdf"
            }
          ]
        },
        "options": {}
      },
      "name": "Set Document Path",
      "type": "n8n-nodes-base.set",
      "typeVersion": 1,
      "position": [
        -1600,
        -1240
      ],
      "id": "be410d8c-c429-4aec-8fe5-cacfe56a3a9c"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.isTooLarge }}",
              "value2": true
            }
          ]
        }
      },
      "name": "Document Too Large?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        -1000,
        -1240
      ],
      "id": "77ee060a-c4d2-42b2-a0a5-6b84282a5bc9"
    },
    {
      "parameters": {
        "jsCode": "// Split document into smaller chunks if too large\nconst text = $input.item.json.cleanedText || '';\nconst maxChunkTokens = 150000; // Maximum tokens per chunk (conservative)\nconst charsPerToken = 4; // Approximate character-to-token ratio\nconst maxCharsPerChunk = maxChunkTokens * charsPerToken;\n\n// Function to find good split points (at paragraph boundaries)\nfunction findSplitPoint(text, approximatePosition) {\n  // Look for paragraph breaks near the desired position\n  const searchWindow = 2000; // Look 2000 chars before and after\n  const startSearch = Math.max(0, approximatePosition - searchWindow);\n  const endSearch = Math.min(text.length, approximatePosition + searchWindow);\n  \n  const searchText = text.substring(startSearch, endSearch);\n  \n  // Look for paragraph breaks (double newlines or dots at end of line)\n  const breaks = [...searchText.matchAll(/\\n\\s*\\n|\\. *\\n/g)];\n  \n  if (breaks.length > 0) {\n    // Find the break closest to our target position\n    let closestBreak = breaks[0];\n    let closestDistance = Math.abs((startSearch + breaks[0].index) - approximatePosition);\n    \n    for (const match of breaks) {\n      const distance = Math.abs((startSearch + match.index) - approximatePosition);\n      if (distance < closestDistance) {\n        closestBreak = match;\n        closestDistance = distance;\n      }\n    }\n    \n    return startSearch + closestBreak.index + closestBreak[0].length;\n  }\n  \n  // If no good break found, just split at space near the position\n  const nearby = text.substring(\n    Math.max(0, approximatePosition - 100), \n    Math.min(text.length, approximatePosition + 100)\n  );\n  \n  const spaceMatch = nearby.match(/\\s/);\n  if (spaceMatch) {\n    return approximatePosition - 100 + spaceMatch.index;\n  }\n  \n  // Last resort - just split at the position\n  return approximatePosition;\n}\n\n// Split the text into manageable chunks\nconst chunks = [];\nlet remaining = text;\nlet chunkNum = 1;\n\nwhile (remaining.length > 0) {\n  if (remaining.length <= maxCharsPerChunk) {\n    // Last chunk fits entirely\n    chunks.push({\n      chunkText: remaining,\n      chunkNum,\n      totalChunks: Math.ceil(text.length / maxCharsPerChunk)\n    });\n    break;\n  }\n  \n  // Find a good split point\n  const splitPoint = findSplitPoint(remaining, maxCharsPerChunk);\n  \n  // Add this chunk\n  chunks.push({\n    chunkText: remaining.substring(0, splitPoint),\n    chunkNum,\n    totalChunks: Math.ceil(text.length / maxCharsPerChunk)\n  });\n  \n  // Continue with remaining text\n  remaining = remaining.substring(splitPoint);\n  chunkNum++;\n}\n\n// Process only the first chunk for now (we'll handle multi-chunk processing separately)\nreturn [{\n  json: {\n    ...$input.item.json,\n    processType: 'chunked',\n    chunkText: chunks[0].chunkText,\n    chunkNum: chunks[0].chunkNum,\n    totalChunks: chunks[0].totalChunks,\n    chunkEstimatedTokens: Math.ceil(chunks[0].chunkText.length / charsPerToken),\n    message: `Document split into ${chunks.length} chunks. Processing chunk 1 of ${chunks.length}.`\n  }\n}];"
      },
      "name": "Split Document",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [
        -760,
        -1340
      ],
      "id": "e3629a38-1f1e-4c0d-be84-2ad8e80c5848"
    },
    {
      "parameters": {
        "jsCode": "// URL for Claude API\nreturn [\n  {\n    json: {\n      ...$input.item.json,\n      // Create the entire API call for Claude\n      anthropicSystemPrompt: \"You are an expert document optimization specialist preparing content for a large language model's KV cache with a 128K token limit. Your goal is to efficiently prepare documents by: 1) Removing redundancy, repetition, and unnecessary verbosity while preserving complete original meaning, 2) Maintaining all technical nuance, critical details, and domain-specific terminology, 3) Optimizing token efficiency without aggressive summarization, 4) Ensuring the document retains its original structure and information hierarchy, 5) Identifying and removing boilerplate text and irrelevant metadata. You are NOT creating a summary. You are preparing the document to fit efficiently in the 128K token window while preserving as much of the original information as possible.\",\n      anthropicUserPrompt: `I need you to optimize the following document for ingestion into an LLM's KV cache with a 128K token limit. Your task is NOT to summarize or simplify the content aggressively. Instead:\\n\\n- Identify and remove redundant phrases, repetitive explanations, duplicated ideas, boilerplate text, and irrelevant metadata\\n- Compress verbose language by rewriting overly wordy sentences more concisely without losing nuance or technical accuracy\\n- Preserve all critical information, original nuance, details, domain-specific terminology, and technical specifics\\n- Maintain the document's original structure and information hierarchy\\n- Retain all examples, code blocks, and technical sequences exactly as they appear\\n- Format the output in clean, well-structured text optimized for token efficiency\\n\\nIf sections appear to add no meaningful information or are purely repetitive, make them more concise but preserve their core meaning.\\n\\nHere is the document to optimize:\\n\\n${$input.item.json.cleanedText}\\n\\nOutput the optimized document that maintains maximum fidelity to the original while reducing token usage where possible.`\n    }\n  }\n];"
      },
      "name": "Prepare Claude API Request",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [
        -760,
        -1100
      ],
      "id": "0dff0b88-d619-4e8e-9529-2c5586afcd93"
    },
    {
      "parameters": {
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            },
            {
              "name": "content-type",
              "value": "application/json"
            },
            {
              "name": "x-api-key",
              "value": "={{ $credential.apiKey }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "{\n  \"model\": \"claude-3-7-sonnet-20250219\",\n  \"max_tokens\": 128000,\n  \"temperature\": 0.1,\n  \"system\": \"{{ $json.anthropicSystemPrompt }}\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"{{ $json.anthropicUserPrompt }}\"\n    }\n  ]\n}",
        "options": {
          "response": {}
        }
      },
      "name": "Claude API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        -1500,
        -960
      ],
      "id": "41a91c46-f1cc-491a-b1ed-116582f925fa"
    },
    {
      "parameters": {
        "jsCode": "// Extract the model's response and prepare output\nlet response = '';\n\ntry {\n  // Extract response from Claude API\n  if ($input.item.json.content && Array.isArray($input.item.json.content)) {\n    // Find the assistant's message content\n    for (const content of $input.item.json.content) {\n      if (content.type === 'text') {\n        response = content.text;\n        break;\n      }\n    }\n  }\n} catch (error) {\n  console.log('Error extracting Claude response:', error.message);\n}\n\nconst fileName = $input.item.json.fileName || 'document';\nconst timestamp = $input.item.json.timestamp || new Date().toISOString().replace(/[:.]/g, '-');\n\n// Generate a meaningful output filename\nconst baseFileName = fileName.replace(/\\.[^/.]+$/, '');\nconst outputFileName = `optimized_${baseFileName}_${timestamp}.txt`;\nconst outputFilePath = `/data/documents/optimized/${outputFileName}`;\n\n// Estimate tokens in optimized text (4 chars per token is a rough estimate)\nconst originalTokens = $input.item.json.estimatedTokens || 0;\nconst optimizedTokens = Math.ceil(response.length / 4);\n\n// Calculate reduction percentage\nconst reductionPercent = originalTokens > 0 \n  ? Math.round((1 - (optimizedTokens / originalTokens)) * 100) \n  : 0;\n\nreturn [{\n  json: {\n    ...$input.item.json,\n    optimizedText: response,\n    outputFileName,\n    outputFilePath,\n    originalTokens,\n    optimizedTokens,\n    reductionPercent\n  }\n}];"
      },
      "name": "Process Claude Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [
        -140,
        -1100
      ],
      "id": "efe78393-6daf-4793-99c9-48611254b02c"
    },
    {
      "parameters": {
        "jsCode": "// Generate a summary of the optimization process\nconst originalTokens = $input.item.json.originalTokens || 0;\nconst optimizedTokens = $input.item.json.optimizedTokens || 0;\nconst reductionPercent = $input.item.json.reductionPercent || 0;\n\nconst summary = {\n  fileName: $input.item.json.fileName,\n  originalPath: $input.item.json.documentPath,\n  optimizedPath: $input.item.json.outputFilePath,\n  originalTokens: originalTokens.toLocaleString(),\n  optimizedTokens: optimizedTokens.toLocaleString(),\n  reductionPercent: `${reductionPercent}%`,\n  timestamp: new Date().toISOString(),\n  status: 'Optimization complete',\n  message: `Document optimized and saved to ${$input.item.json.outputFilePath}`,\n  readyForKVCache: true\n};\n\nreturn [{ json: summary }];"
      },
      "name": "Generate Optimization Summary",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [
        260,
        -1100
      ],
      "id": "694358c9-cd49-40b4-9345-76eb52aa5da0"
    },
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "errorMessage",
              "value": "={{ $json.tokenWarning }}"
            },
            {
              "name": "status",
              "value": "Document is too large"
            }
          ]
        },
        "options": {}
      },
      "name": "Document Size Warning (Placeholder)",
      "type": "n8n-nodes-base.set",
      "typeVersion": 1,
      "position": [
        -540,
        -1340
      ],
      "id": "83f6d908-7b99-4a33-b92d-963fa73cfaa6",
      "notes": "This is a placeholder for how you would handle large documents. In practice, you would implement a chunking strategy here."
    },
    {
      "parameters": {},
      "name": "Read Binary File2",
      "type": "n8n-nodes-base.readBinaryFile",
      "typeVersion": 1,
      "position": [
        -1400,
        -1240
      ],
      "id": "2682d672-1cf5-40b0-94b2-22b1ff37c9b6"
    },
    {
      "parameters": {
        "jsCode": "// Convert binary data to text\nlet text = '';\nlet fileName = '';\n\ntry {\n  // Try to convert binary data to text\n  if (items[0].binary && items[0].binary.data) {\n    text = Buffer.from(items[0].binary.data, 'base64').toString('utf-8');\n    \n    // Get the filename from binary data or use the path\n    if (items[0].binary.fileName) {\n      fileName = items[0].binary.fileName;\n    } else {\n      // Extract filename from path\n      const path = items[0].json.documentPath || '';\n      fileName = path.split('/').pop() || 'document';\n    }\n  }\n} catch (error) {\n  // If there's an error, we'll handle it gracefully\n  console.log('Error converting binary data:', error.message);\n}\n\n// Clean up the text by removing excess whitespace\nconst cleaned = text.replace(/\\s+/g, ' ').trim();\n\n// Estimate token count (rough estimate: 4 characters per token)\nconst estimatedTokens = Math.ceil(cleaned.length / 4);\n\n// Check if document might exceed Claude's token limit\nconst isTooLarge = estimatedTokens > 180000; // Setting safety margin below 200K\n\n// Add the cleaned text to a field called chatInput\nreturn [{\n  json: {\n    chatInput: cleaned,\n    originalText: text,\n    cleanedText: cleaned,\n    fileName: fileName,\n    documentPath: items[0].json.documentPath,\n    estimatedTokens,\n    isTooLarge,\n    tokenWarning: isTooLarge ? `Warning: Document is approximately ${estimatedTokens.toLocaleString()} tokens, which may exceed Claude's limit.` : '',\n    timestamp: new Date().toISOString().replace(/[:.]/g, '-')\n  }\n}];"
      },
      "name": "Initial Text Cleanup2",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [
        -1200,
        -1240
      ],
      "id": "d337147d-79ad-47f7-8115-3752c4bcd633"
    },
    {
      "parameters": {
        "options": {}
      },
      "name": "Write Optimized Document1",
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        60,
        -1100
      ],
      "id": "756505aa-ed39-4fe0-8b0b-c64f109a5d3e"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -520,
        -860
      ],
      "id": "d1824b26-c91b-48bf-9b55-ba65f5fb8cf1",
      "name": "Anthropic Chat Model"
    },
    {
      "parameters": {
        "messages": {
          "messageValues": [
            {
              "message": "You are an expert document optimization specialist preparing content for a large language model's KV cache with a 128K token limit. Your goal is to efficiently prepare documents by: 1) Removing redundancy, repetition, and unnecessary verbosity while preserving complete original meaning, 2) Maintaining all technical nuance, critical details, and domain-specific terminology, 3) Optimizing token efficiency without aggressive summarization, 4) Ensuring the document retains its original structure and information hierarchy, 5) Identifying and removing boilerplate text and irrelevant metadata. You are NOT creating a summary. You are preparing the document to fit efficiently in the 128K token window while preserving as much of the original information as possible."
            },
            {
              "type": "HumanMessagePromptTemplate",
              "message": "I need you to optimize the following document for ingestion into an LLM's KV cache with a 128K token limit. Your task is NOT to summarize or simplify the content aggressively. Instead:  - Identify and remove redundant phrases, repetitive explanations, duplicated ideas, boilerplate text, and irrelevant metadata - Compress verbose language by rewriting overly wordy sentences more concisely without losing nuance or technical accuracy - Preserve all critical information, original nuance, details, domain-specific terminology, and technical specifics - Maintain the document's original structure and information hierarchy - Retain all examples, code blocks, and technical sequences exactly as they appear - Format the output in clean, well-structured text optimized for token efficiency  If sections appear to add no meaningful information or are purely repetitive, make them more concise but preserve their core meaning.  Here is the document to optimize:  [DOCUMENT TEXT HERE]  Output the optimized document that maintains maximum fidelity to the original while reducing token usage where possible."
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        -520,
        -1100
      ],
      "id": "d941fcc3-76b7-4fa8-a3b3-da23084ef1e8",
      "name": "Basic LLM Chain"
    },
    {
      "parameters": {
        "operation": "createFromText",
        "driveId": {
          "__rl": true,
          "mode": "list",
          "value": "My Drive"
        },
        "folderId": {
          "__rl": true,
          "mode": "list",
          "value": "root",
          "cachedResultName": "/ (Root folder)"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        60,
        -1280
      ],
      "id": "680ed81b-c3ad-45bb-bd9b-a99954a3a606",
      "name": "Placeholede"
    },
    {
      "parameters": {
        "pollTimes": {
          "item": [
            {
              "mode": "everyMinute"
            }
          ]
        },
        "triggerOn": "specificFolder",
        "folderToWatch": {
          "__rl": true,
          "mode": "list",
          "value": ""
        }
      },
      "type": "n8n-nodes-base.googleDriveTrigger",
      "typeVersion": 1,
      "position": [
        -860,
        -700
      ],
      "id": "6057b990-87a7-4667-984c-805ecfca1b63",
      "name": "Placeholder Trigger"
    },
    {
      "parameters": {
        "content": "",
        "height": 640,
        "width": 2120
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1640,
        -1360
      ],
      "id": "7f33e231-03fd-4037-827b-e43b7f8d844e",
      "name": "Sticky Note3"
    }
  ],
  "pinData": {},
  "connections": {
    "Set Workflow Params": {
      "main": [
        [
          {
            "node": "Read Document File1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call CAG Bridge": {
      "main": [
        [
          {
            "node": "Workflow Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read Document File1": {
      "main": [
        [
          {
            "node": "Write Temp File1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write Temp File1": {
      "main": [
        [
          {
            "node": "Call CAG Bridge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Document Path": {
      "main": [
        [
          {
            "node": "Read Binary File2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Document Too Large?": {
      "main": [
        [
          {
            "node": "Split Document",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare Claude API Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Claude API Request": {
      "main": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude API": {
      "main": [
        []
      ]
    },
    "Process Claude Response": {
      "main": [
        [
          {
            "node": "Write Optimized Document1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Placeholede",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Document": {
      "main": [
        [
          {
            "node": "Document Size Warning (Placeholder)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read Binary File2": {
      "main": [
        [
          {
            "node": "Initial Text Cleanup2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Initial Text Cleanup2": {
      "main": [
        [
          {
            "node": "Document Too Large?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write Optimized Document1": {
      "main": [
        [
          {
            "node": "Generate Optimization Summary",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain": {
      "main": [
        [
          {
            "node": "Process Claude Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Placeholder Trigger": {
      "main": [
        [
          {
            "node": "Set Workflow Params",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "0ec75cfa-3f40-4abb-b2b4-a0cf7b18dd9e",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "031b645215ae9b6f375e501b38c32a541dca72c391120eef6f1ad1015f3ee67f"
  },
  "id": "plJ9X3xWuXNrDKm5",
  "tags": []
}