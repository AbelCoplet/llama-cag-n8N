version: '3.8'

services:
  n8n:
    image: n8nio/n8n:latest
    container_name: llamacag-n8n
    restart: unless-stopped
    ports:
      - "${N8N_PORT:-5678}:5678"
    environment:
      - N8N_PORT=5678
      - N8N_PROTOCOL=${N8N_PROTOCOL:-http}
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_PERSONALIZATION_ENABLED=false
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET}
      - DB_TYPE=${DB_TYPE:-postgres}
      - DB_POSTGRESDB_HOST=${DB_HOST:-db}
      - DB_POSTGRESDB_PORT=${DB_PORT:-5432}
      - DB_POSTGRESDB_DATABASE=${DB_NAME:-llamacag}
      - DB_POSTGRESDB_USER=${DB_USER:-llamacag}
      - DB_POSTGRESDB_PASSWORD=${DB_PASSWORD}
      - LLAMACPP_PATH=/usr/local/llamacpp
      - LLAMACPP_MODEL_PATH=/usr/local/llamacpp/models/${LLAMACPP_MODEL_NAME:-gemma-4b.gguf}
      - LLAMACPP_MODEL_NAME=${LLAMACPP_MODEL_NAME:-gemma-4b.gguf}
      - LLAMACPP_KV_CACHE_DIR=/data/kv_caches
      - LLAMACPP_TEMP_DIR=/data/temp_chunks
      - LLAMACPP_MAX_CONTEXT=${LLAMACPP_MAX_CONTEXT:-128000}
      - LLAMACPP_GPU_LAYERS=${LLAMACPP_GPU_LAYERS:-0}
      - LLAMACPP_THREADS=${LLAMACPP_THREADS:-4}
      - LLAMACPP_BATCH_SIZE=${LLAMACPP_BATCH_SIZE:-1024}
    volumes:
      - n8n_data:/home/node/.n8n
      - ./scripts/bash:/usr/local/bin/cag-scripts:ro
      - ${LLAMACPP_PATH:-~/Documents/llama.cpp}:/usr/local/llamacpp:ro
      - ${LLAMACPP_KV_CACHE_DIR:-~/cag_project/kv_caches}:/data/kv_caches
      - ${LLAMACPP_TEMP_DIR:-~/cag_project/temp_chunks}:/data/temp_chunks
      - ${DOCUMENTS_FOLDER:-~/Documents/cag_documents}:/data/documents
    depends_on:
      db:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 8G  # Adjusted for large context window models
        reservations:
          memory: 2G

  n8n-import:
    image: n8nio/n8n:latest
    container_name: llamacag-n8n-import
    entrypoint: /bin/sh
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/backup/credentials && n8n import:workflow --separate --input=/backup/workflows"
    volumes:
      - ./n8n/workflows:/backup/workflows
      - n8n_data:/home/node/.n8n
    depends_on:
      - db

  db:
    image: postgres:14
    container_name: llamacag-db
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${DB_USER:-llamacag}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME:-llamacag}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/schema.sql:/docker-entrypoint-initdb.d/schema.sql
    ports:
      - "${DB_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-llamacag}"]
      interval: 10s
      timeout: 5s
      retries: 5
      
  # New CAG Bridge service
  cag-bridge:
    image: python:3.9
    container_name: llamacag-bridge
    restart: unless-stopped
    volumes:
      - ./scripts/bash:/usr/local/bin/cag-scripts:ro
      - ${LLAMACPP_PATH:-~/Documents/llama.cpp}:/usr/local/llamacpp:ro
      - ${LLAMACPP_KV_CACHE_DIR:-~/cag_project/kv_caches}:/data/kv_caches
      - ./bridge:/app
    working_dir: /app
    command: "python cag_bridge.py"
    environment:
      - MASTER_KV_CACHE=/data/kv_caches/${MASTER_KV_CACHE:-master_cache.bin}
      - LLAMACPP_MODEL_PATH=/usr/local/llamacpp/models/${LLAMACPP_MODEL_NAME:-gemma-4b.gguf}
      - LLAMACPP_MAX_CONTEXT=${LLAMACPP_MAX_CONTEXT:-128000}
      - LLAMACPP_THREADS=${LLAMACPP_THREADS:-4}
    ports:
      - "${CAG_BRIDGE_PORT:-8000}:8000"

volumes:
  n8n_data:
  postgres_data: